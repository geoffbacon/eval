{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating Batchkarov et al. (2016) _A critique of word similarity as a method for evaluating distributional semantic models_\n",
    "\n",
    "This paper argues that the intrinsic evaluation of word embeddings with existing word similarity datasets is problematic. In particular, they argue the following:\n",
    "\n",
    "- that \"word similarity\" doesn't make sense outside of the context of a specific task,\n",
    "- that inter-annotator agreement is low on existing datasets,\n",
    "- and that the small size of existing datasets leads to too much variation in single number measures. \n",
    "\n",
    "I understand their conclusion to be that while word similarity can be used as a coarse evaluation, extrinsic methods should be preferred over intrinsic methods. They also have an interesting proposal for salvaging word similarity as an evaluation method, namely, use word similarity datasets that give increasingly worse evaluations to embeddings as random noise is added.\n",
    "\n",
    "While Batchkarov et al. do make [their code](https://github.com/mbatchkarov/repeval2016) public, I'd like to do it myself as a learning experience.\n",
    "\n",
    "They explore five word similarity datasets:\n",
    "\n",
    "|  Name  \t|              Paper             \t|\n",
    "|:------:\t|:------------------------------\t|\n",
    "|   RG   \t| Rubenstein & Goodenough (1965) \t|\n",
    "|   MC   \t|     Miller & Charles (1995)    \t|\n",
    "|  WS353 \t|    Finkelstein et al. (2001)   \t|\n",
    "|   MEN  \t|       Bruni et al. (2014)      \t|\n",
    "| SimLex \t|       Hill et al. (2015)       \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of word similarity\n",
    "\n",
    "Their first point is that \"word similarity\" could mean many different things. They note that many word similarity datasets do not distinguish/are not balanced for lexical semantic relationships (synonymy, antonymy, homonymy, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Are the five datasets balanced balanced across lexical relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Is there a relationship between lexical relationship and empirical similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Do the five datasets have POS distributions similar to natural text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Larger question: Are the five datasets representative of English? Are these words typical English words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They next note that the similarity judgements assigned to the same pair across datasets differs widely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../evaluate/data'\n",
    "\n",
    "rg65_path = 'rg-65/rg-65.csv'\n",
    "mc_path = 'mc/mc.csv'\n",
    "ws353_path = 'ws-353/ws-353.csv'\n",
    "men_path = 'men/men.csv'\n",
    "simlex_path = 'simlex/simlex.csv'\n",
    "\n",
    "rg65 = pd.read_csv(os.path.join(data_dir, rg65_path))\n",
    "mc = pd.read_csv(os.path.join(data_dir, mc_path))\n",
    "ws353 = pd.read_csv(os.path.join(data_dir, ws353_path))\n",
    "men = pd.read_csv(os.path.join(data_dir, men_path))\n",
    "simlex = pd.read_csv(os.path.join(data_dir, simlex_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>which_set?</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "      <td>set1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "      <td>set1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>set1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "      <td>set1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "      <td>set1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1     word2  similarity which_set?     1     2     3     4     5  \\\n",
       "0      love       sex        6.77       set1   9.0   6.0   8.0   8.0   7.0   \n",
       "1     tiger       cat        7.35       set1   9.0   7.0   8.0   7.0   8.0   \n",
       "2     tiger     tiger       10.00       set1  10.0  10.0  10.0  10.0  10.0   \n",
       "3      book     paper        7.46       set1   8.0   8.0   7.0   7.0   8.0   \n",
       "4  computer  keyboard        7.62       set1   8.0   7.0   9.0   9.0   8.0   \n",
       "\n",
       "      6     7     8     9    10    11    12    13  14  15  16  \n",
       "0   8.0   8.0   4.0   7.0   2.0   6.0   7.0   8.0 NaN NaN NaN  \n",
       "1   9.0   8.5   5.0   6.0   9.0   7.0   5.0   7.0 NaN NaN NaN  \n",
       "2  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0 NaN NaN NaN  \n",
       "3   9.0   7.0   6.0   7.0   8.0   9.0   4.0   9.0 NaN NaN NaN  \n",
       "4   8.0   7.0   7.0   6.0   8.0  10.0   3.0   9.0 NaN NaN NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws353.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concretely, they point out that the pair \"chicken-rice\" has a normalized score of 0.14 in SimLex but 0.68 in MEN. And that the pair \"man-woman\" has 0.33 in SimLex but 0.84 in MEN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>similarity</th>\n",
       "      <th>word1_concreteness</th>\n",
       "      <th>word2_concreteness</th>\n",
       "      <th>concreteness_quartile</th>\n",
       "      <th>nelson_norms</th>\n",
       "      <th>top_333_in_nelson</th>\n",
       "      <th>similarity_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>chicken</td>\n",
       "      <td>rice</td>\n",
       "      <td>N</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1 word2 POS  similarity  word1_concreteness  word2_concreteness  \\\n",
       "451  chicken  rice   N        1.43                 4.8                4.86   \n",
       "\n",
       "     concreteness_quartile  nelson_norms  top_333_in_nelson  similarity_sd  \n",
       "451                      4          0.27                  0           1.47  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlex[(simlex['word1']=='chicken') & (simlex['word2']=='rice')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity_out_of_50</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>chicken</td>\n",
       "      <td>rice</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1 word2  similarity_out_of_50  similarity\n",
       "909  chicken  rice                  34.0         6.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men[(men['word1']=='chicken') & (men['word2']=='rice')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, I have two points here:\n",
    "- Is it OK to normalize similarity scores that weren't originally on a 1-10 scale? (What if the true measurement isn't linear?) I'll put this aside for now.\n",
    "- What other word pairs do these datasets have in common? Let's take a look.\n",
    "\n",
    "Merge datasets together on the two word columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = ['rg65', 'mc', 'ws353', 'men']\n",
    "df = simlex[['word1', 'word2', 'similarity']]\n",
    "df.columns = ['word1', 'word2', 'simlex']\n",
    "\n",
    "for name in datasets:\n",
    "    other = eval(name)[['word1', 'word2', 'similarity']]\n",
    "    other.columns = ['word1', 'word2', name]\n",
    "    df = pd.merge(df, other, how='outer', on=['word1', 'word2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word pairs present in more than one dataset will less than four NaN in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duplicates = df[['rg65', 'mc', 'ws353', 'men', 'simlex']].isnull().sum(axis=1) < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[duplicates][['simlex', 'rg65', 'mc', 'ws353', 'men']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is hacky, I'd like to have a better solution than this.\n",
    "values = df[duplicates][['simlex', 'rg65', 'mc', 'ws353', 'men']].values\n",
    "distances = []\n",
    "for row in values:\n",
    "    row = row.reshape(-1,1)\n",
    "    d = pdist(row)\n",
    "    distances.extend([i for i in d if not np.isnan(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the distribution of (absolute) discrepancies between the five datasets on a 10-point scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD3CAYAAADrGWTVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPYvRlWQ9iINidUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f190f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(distances, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.967480221776942e-08, 1.8331562835698065)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.halfnorm.fit(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distances are centered close enough to 0, with std 1.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, as Batchkarov-et-al point out, these datasets do give different estimates of word similarity from each other. The two examples they give are from the upper limit, as most absolute differences are less than 2. \n",
    "\n",
    "They go from this to the argument that a single global measure of word similarity is not appropriate, that each downstream task defines its own similarity measure. I can be sympathetic to that view, but I'm not sure of the link between inter-dataset variabaility and task-specific word similarity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjectivity and task difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
